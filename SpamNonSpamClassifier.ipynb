{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classifier for Spam/Non-Spam Emails\n",
    "\n",
    "**DATASET**\n",
    "- A Spambase dataset from the UCI Machine Learning Repository: http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "- The Spambase data set consists of 4,601 e-mails, of which 1,813 are spam (39.4%). The data set archive contains a processed version of the e-mails wherein 57 real-valued features have been extracted and the spam/non-spam label has been assigned. The data set archive contains a description of the features extracted as well as some simple statistics over those features.\n",
    "\n",
    "**AIM**\n",
    "- Build a classification model which will be able to filter spam/not spam emails. \n",
    "- Compare the performance of a few classification algorithms and choose the best performing one. \n",
    "- Evaluate the models using k-fold cross-validation. \n",
    "- Reduce the false postives i.e marking good mail as spam.\n",
    "\n",
    "**EVALUATION/OUTPUT**\n",
    "- A table with one row per fold showing the false positive, false negative, and overall error rates, and one final row corresponding to the average error rates across all folds for our best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Importing all the required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following class stores all the relevant details regarding algorithms. It contains the following computed details in a np-array for all the kfolds:**\n",
    "- True Negative\n",
    "- True Positive\n",
    "- False Negative\n",
    "- False Positive\n",
    "- Accuracy across K-Folds\n",
    "- Error rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: Creating a class to store the output metrics for all the folds algorithm wise. \n",
    "class AlgorithmOutputs:\n",
    "    \n",
    "    def __init__(self, algo, tn, fp, fn, tp):\n",
    "        self.algo = algo\n",
    "        self.tn = tn\n",
    "        self.fp = fp\n",
    "        self.fn = fn\n",
    "        self.tp = tp\n",
    "        self.total_accuracy = self.compute_accuracy()\n",
    "\n",
    "    def compute_error_rates(self):\n",
    "        error_rate = (self.fp + self.fn)/(self.tn + self.fp + self.tp + self.fn)\n",
    "        return error_rate\n",
    "    \n",
    "    def compute_accuracy(self):\n",
    "        error_rates = self.compute_error_rates()\n",
    "        return 1 - np.squeeze(np.sum(error_rates))/error_rates.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- As stated above, we are using the spambase dataset from the UCI Machine Learning Repository - http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "- For reading the data we are using _read_csv_ function provided by pandas. It reads a data file into a DataFrame.\n",
    "- Data preprocessing is an important step in ML as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn. Therefore, it is extremely important that we preprocess our data before feeding it into our model. \n",
    "- Irregular distribution of values may suffer from poor performance during learning and sensitivity to input values resulting in higher error. \n",
    "- One can understand how varied the data is from 'Attribute Statistics' in https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.DOCUMENTATION\n",
    "- For normalization of data, we are going to use MinMaxScaler. \n",
    "\n",
    "**We can always start by fitting our model to raw, normalized and standardized data and compare the performance for best results.**\n",
    "\n",
    "For the above given dataset the results were more or less the same. But feature scaling is a good technique when the machine learning algorithms are sensitive to feature scaling such as gradient decsent which tends to converge faster to the local maximum/minimum if the features are scaled properly. However, there are few ML algorithms such as tree based algoithms which are virtually invariant to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Preparing Dataset\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data')\n",
    "with urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names') as response:\n",
    "    data_col = response.read()\n",
    "    data_col = data_col.decode('utf-8')\n",
    "# Extracting column names from spambase.names\n",
    "data_col = data_col.split('|')\n",
    "data_col = data_col[len(data_col)-1].splitlines()\n",
    "data_col = data_col[2:]\n",
    "data_col_details =  {}\n",
    "for colDetails in data_col:\n",
    "    colDetails = colDetails.split(':')\n",
    "    data_col_details[colDetails[0]] = ''.join(e for e in colDetails[1] if e.isalnum())\n",
    "data_col_details['Spam'] = 'nominal'\n",
    "data_col_names = data_col_details.keys()\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1:]\n",
    "\n",
    "# STEP 4: Preprocessing the data before allowing the models to learn from our dataset.\n",
    "# Transform features by scaling each feature to a given range.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, our aim is to classify emails as Spam or Non-Spam emails, it is important to make false-positive (classifying a Non-Spam email as a Spam email) as minimum as possible. To handle this, we will make some changes in how we will predict output. We will try to change the cutoff probabilities to reduce the number of false positives. While converting predicted output to probabilities, **we will instruct the model to classify only those with probability more than 0.9 to be marked as spam.** It can decrease the overall accuracy, but it's better to read some non-important email in the inbox, than leaving out some important messages in the spam. \n",
    "\n",
    "Default cutoff's to classify an event are 0.5. Increasing or decreasing this threshold might affest your accuarcy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Creating Custom Scorers as per the output required.\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "def accuracy(y_true, y_pred): return accuracy_score(y_true, (y_pred > 0.5)) # To reduce the number of false positives\n",
    "scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "           'fp': make_scorer(fp), 'fn': make_scorer(fn), 'accuracy': make_scorer(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Once, we are done with processing the data and loading it into appropriate data structures, let's analyse which classification algorithms will perform better. In the end, the accuracy score and confusion matrix will tell us how well our model works.\n",
    "\n",
    "**Some of the models which can be used for the given dataset and the classification problem are as follows:** \n",
    "\n",
    "- **DecisionTree**: A faster way to give accurate results on large data set.\n",
    "\n",
    "- **Random Forest**: A tree based algorithm which is designed to handle missing values and mantain accuracy for a large data size. It works well with cross validation. One can think of Random Forest Algorithm a way of combining multple Decision Tree together. RFs train each tree independently, using a random sample of the data.\n",
    "\n",
    "- **Gradient Boosting**: It is similar to Random Forest but GBT build trees one at a time, where each new tree helps to correct errors made by previously trained tree. \n",
    "\n",
    "- **Logistic Regression**: It measures the relationship between the categorical dependent variable and one or more independent variables by calculating probabilities using a logistic function.\n",
    "\n",
    "- **MultinomialNB**: Naive Bayes is very popular probabilistic classifier which is based on the assumption that features are independent to each other. There are three types of Naive Bayes model under the scikit-learn library:\n",
    "    1. **Gaussian:** It is used in classification and it assumes that features follow a normal distribution.\n",
    "    2. **Multinomial:** It is used for discrete counts. \n",
    "    3. **Bernoulli:** It is useful if your feature vectors are binary (i.e. zeros and ones)\n",
    "    \n",
    "_Please note for all the listed models we have made an educated estimation for the parameters. Parameter tunings has been done to give us the best results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning relies on experimental results than theory, there doesn't exist any predefined set of values which will sure shot give you the best results. Therefore, if we have to find the best parameters for our data and problem, trial and error is the best plausible option. We can determine the optimal settings by trying multiple combinations and evaluate the performance of each model. However, evaluating each model only on the training set can lead to overfitting. \n",
    "\n",
    "**Cross Validation (CV) is the technique to overcome overfitting.** We split our data into a training and a testing set. In K-Fold CV, we split our training data into K subsets, called folds. We then iteratively fit the model K times, each time training the data on K-1 of the folds and evaluating on the Kth fold (called the validation data). To elucidate, consider fitting a model with K = 10. In the first iteration, we train our model on the first nine folds and evaluate on the tenth. We repeat this procedure 9 more times, each time evaluating on a different fold. At the very end of training, we average the performance on each of the folds to come up with final validation metrics for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now testing algorithms\n",
      "Accuracy of DecisionTree is 90.93%\n",
      "Accuracy of RandomForest is 93.96%\n",
      "Accuracy of GradientBoosting is 93.33%\n",
      "Accuracy of MultinomialNB is 87.54%\n",
      "Accuracy of BernoulliNB is 88.50%\n",
      "Accuracy of LogisticRegression is 91.07%\n"
     ]
    }
   ],
   "source": [
    "#Step 6: Selecting various classification algorithms/models for comparison. \n",
    "# Hyperparameter tuning done using the calculated guess. Algorithms and their parameters are selected depending \n",
    "# upon our requirement and dataset knowledge. \n",
    "algorithms = {\n",
    "        \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10),\n",
    "        \"RandomForest\": ske.RandomForestClassifier(n_estimators=50),\n",
    "        \"GradientBoosting\": ske.GradientBoostingClassifier(n_estimators=50),\n",
    "        \"MultinomialNB\": MultinomialNB(),\n",
    "        \"BernoulliNB\": BernoulliNB(),\n",
    "        \"LogisticRegression\": LogisticRegression(solver='liblinear', penalty='l1')\n",
    "}\n",
    "results = []\n",
    "print(\"\\nNow testing algorithms\")\n",
    "\n",
    "#Step 7: Performing K-Folds CV(K=10) on our models. \n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    # scikit-learn allows us to perform K-Folds CV using the below function. \n",
    "    # It evaluate metrics by cross-validation. \n",
    "    cv_results = cross_validate(clf, X, y.values.ravel(), cv=10, scoring=scoring) \n",
    "    out = AlgorithmOutputs(algo, cv_results['test_tn'], cv_results['test_fp'], \n",
    "                                            cv_results['test_fn'], cv_results['test_tp'])\n",
    "    print(\"Accuracy of %s is %0.2f\" % (algo, out.total_accuracy * 100) + \"%\")\n",
    "    results.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** gives the maximum accuracy. It's accuracy is ~94%. Also, RF ensures the **minimum false positive rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner Algorithm is RandomForest with error rate of 6.04%.\n"
     ]
    }
   ],
   "source": [
    "#Step 8: Determining the most accurate model which gives you the least possible false positive.\n",
    "def compute_max(p):\n",
    "    return p.total_accuracy\n",
    "winner = max(results, key=compute_max) # to determine the model which gives us the maximum accuracy.\n",
    "print(\"Winner Algorithm is %s with error rate of %0.2f\" %(winner.algo, (1 - winner.total_accuracy)*100) + \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "We will show the output in a form of a table (DataFrame) with one row per fold showing the false positive, false negative, and overall error rates, and add one final row corresponding to the average error rates across all folds for our best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>Error Rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.054348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.054348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.063043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.047826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.036957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.028261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.026087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.145652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Overall/Average</td>\n",
       "      <td>11.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.060435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fold  False Positive  False Negative  Error Rates\n",
       "0                 1             5.0            20.0     0.054348\n",
       "1                 2             9.0            16.0     0.054348\n",
       "2                 3             6.0            23.0     0.063043\n",
       "3                 4             5.0            17.0     0.047826\n",
       "4                 5             5.0            12.0     0.036957\n",
       "5                 6            11.0             9.0     0.043478\n",
       "6                 7             4.0             9.0     0.028261\n",
       "7                 8             4.0             8.0     0.026087\n",
       "8                 9            35.0            13.0     0.104348\n",
       "9                10            34.0            33.0     0.145652\n",
       "10  Overall/Average            11.8            16.0     0.060435"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 9: For the winner algorithm, generating results folds wise. Also, showing the final/overall error rate. \n",
    "output_data = {'Fold' : np.arange(1, 11, 1).tolist(), 'False Positive' : winner.fp, \n",
    "               'False Negative' : winner.fn, 'Error Rates' : winner.compute_error_rates()}\n",
    "df = pd.DataFrame(data=output_data)\n",
    "df = df.append(pd.Series(df.mean()), ignore_index=True)\n",
    "df.iloc[-1, df.columns.get_loc('Fold')] = 'Overall/Average'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESULT\n",
    "We have successfully created and implemented classification model using multiple algorithms with parameter tuning. We have evaluated the models using kfold validation. We identified that in our case the **random forest** algorithm worked better than all the algorithms with the error rate ~6%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
